{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas   as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creiamo un unico dataframe che contiene tutto\n",
    "Labels(OK)  Degree(OK)\tBetweenness(OK)\tVoltage\tLatitude(OK) Longitude(OK) Old_Labels(OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PowerGrid  = pd.read_csv('./PowerGrid/node_coordinates.nodelist', delimiter=' ',names=[\"Label\",\"Latitude\",\"Longitude\"],header=None)\n",
    "degree        = pd.read_csv(\"./PowerGrid/gridkit_north_america.nodelist\", delimiter=' ',names=[\"Label\",\"Degree\",\"node_betweenness\"],header=0)\n",
    "labels        = pd.read_csv(\"./PowerGrid/old_new_labels.txt\", header=None, sep=\" \", names=[\"old_labels\", \"new_labels\"])\n",
    "\n",
    "df_Nodes = pd.DataFrame(columns=[ \"Degree\",\"Betweenness\",\"Voltage\",\"Latitude\",\"Longitude\",\"Old_Labels\"], \n",
    "                            index = df_PowerGrid[\"Label\"])\n",
    "df_Nodes[\"Latitude\"]  = df_PowerGrid[\"Latitude\"]\n",
    "df_Nodes[\"Longitude\"] = df_PowerGrid[\"Longitude\"]\n",
    "df_Nodes[\"Degree\"] = degree[\"Degree\"]\n",
    "df_Nodes[\"Betweenness\"] = degree[\"node_betweenness\"]\n",
    "df_Nodes[\"Old_Labels\"] = labels[\"old_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qui prepariamo la colonna del voltaggio\n",
    "grid   = pd.read_csv('./PowerGrid/gridkit_north_america-highvoltage-vertices_original.csv',delimiter=',',index_col=\"v_id\")\n",
    "\n",
    "# Prima selezioniamo i nodi connessi coi vecchi labels salvati in old_labels, infatti grid ha 16174, mentre df_Nodes (i nodi connessi) sono 16167, quindi escludiamo i 7 mancanti\n",
    "grid = grid.loc[labels[\"old_labels\"]]\n",
    "\n",
    "# Riportiamo tutto ai nuovi indici\n",
    "grid.rename({k:v for k,v in zip(labels[\"old_labels\"],labels[\"new_labels\"])}, inplace=True) # Relabelling old to new indices\n",
    "\n",
    "# Given that some stations have multiple power lines, this function takes the average\n",
    "def avg_voltage(volt_list):\n",
    "    volt = []\n",
    "    for item in volt_list:\n",
    "        x = str(item).split(\";\")\n",
    "        x = [float(y) for y in x] if len(x) > 1 else float(x[0])\n",
    "        x = sum(x) / len(x) if isinstance(x, list) else x\n",
    "        volt.append(x)\n",
    "    return volt\n",
    "\n",
    "# grid[\"voltage\"] =  avg_voltage(grid[\"voltage\"]) \n",
    "\n",
    "df_Nodes[\"Voltage\"]    = avg_voltage(grid[\"voltage\"]) \n",
    "df_Nodes[\"Frequency\"]  = grid[\"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qui ci occupiamo del tipo di griglia\n",
    "grid[\"typ\"] \n",
    "unique_list = list(set(grid[\"typ\"])) # Elementi unici\n",
    "my_dict = {'sub_station': 'substation'} # Relabelling\n",
    "\n",
    "type_grid = [my_dict.get(item, item) for item in grid[\"typ\"]]\n",
    "df_Nodes[\"Type\"] = type_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Nodes_Final = df_Nodes.reindex(columns=['Degree', 'Betweenness', 'Voltage', 'Type', 'Frequency','Latitude', 'Longitude',   'Old_Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Nodes_Final.to_csv(\"./PowerGrid/vertices_grid.csv\", sep=' ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network of US power grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"./PowerGrid/gridkit_north_america.el\",nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.504113317251191\n"
     ]
    }
   ],
   "source": [
    "A = [value[1] for value in G.degree]\n",
    "avgD = sum(A)/len(A)  # Mean degree\n",
    "print(avgD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 2-core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.k_core(G,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11404"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G2.nodes())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check nodes in LCC (Largest connected component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [item for item in nx.connected_components(G)]\n",
    "\n",
    "C = list(nx.connected_components(G))\n",
    "for compon in C:\n",
    "    print(len(compon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcc = [int(x) for x in C[1]]   # Nodes in LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Lcc nodes in a file\n",
    "with open('./PowerGrid/Lcc_nodelist.txt', 'w') as file:\n",
    "    for number in Lcc:\n",
    "        file.write(str(number) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column to the full power grid dataframe \n",
    "df_PowerGrid = pd.read_csv(\"./PowerGrid/vertices_grid.csv\", sep=\" \",index_col=\"Label\")\n",
    "df_PowerGrid.loc[Lcc,\"2-core_lcc\"] = int(1)\n",
    "df_PowerGrid[\"2-core_lcc\"].fillna(0,inplace=True)\n",
    "df_PowerGrid[\"2-core_lcc\"] = df_PowerGrid[\"2-core_lcc\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PowerGrid.to_csv(\"./PowerGrid/vertices_grid_2.csv\", sep=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute betweenness with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nx.betweenness_centrality(G)  # About 9 min to compute for 16k nodes\n",
    "d= {int(key):value for key,value in b.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(d.values(),30,range=(0.001,0.02));\n",
    "# dd =G.degree()\n",
    "# dd = {int(key):value for key,value in dict(dd).items()}\n",
    "nodes = pd.DataFrame({'node_degree':dd,'node_betweenness':d},).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes.to_csv('./Data/PowerGrid/test_bet.nodelist',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nodes[\"node_degree\"],nodes[\"node_betweenness\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggi edgelist originale e cambia i labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"./Data/PowerGrid/gridkit-north_america_original.el\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename labels from 0 to N-1\n",
    "old_labels = G.nodes()\n",
    "GG = nx.convert_node_labels_to_integers(G,ordering=\"default\")  # Inherit ordering from G.nodes() (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = list((d for n, d in GG.degree()))\n",
    "nodelist = [int(string) for string in [n for n,d in GG.degree()]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva la nodelist del grafo riordinato coi nuovi labels\n",
    "with open('gridkit_north_america-highvoltage-vertices.nodelist', 'w') as f:\n",
    "    for a,b in zip(nodelist,degree_sequence):\n",
    "        f.write(str(a) + \" \" + str(b) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva la nodelist del grafo originale\n",
    "degree_sequence_old = list((d for n, d in G.degree()))\n",
    "nodelist_old        = [int(string) for string in [n for n,d in G.degree()]]\n",
    "with open('gridkit_north_america-highvoltage-vertices_origin.nodelist', 'w') as f:\n",
    "    for a,b in zip(nodelist_old, degree_sequence_old):\n",
    "        f.write(str(a) + \" \" + str(b) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva la edgelist del nuovo grafo\n",
    "with open('gridkit_north_america-highvoltage-vertices.el', 'w') as f:\n",
    "    for a,b in GG.edges():\n",
    "        f.write(str(a) + \" \" + str(b) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva la corrispondenza old_labels - new_labels\n",
    "with open('old_new_labels.txt', 'w') as f:\n",
    "    for a,b in zip(old_labels,GG.nodes()):\n",
    "        f.write(str(a) + \" \" + str(b) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrai latitudine e longitudine dal file originale e salva i risultati usando i nuovi_label\n",
    "Prendiamo la nodelist con i nuovi label, per ogni elemento troviamo il corrispondente nel file **old_new_label**, infine trovato questo corrispondente lo cerchiamo nel dataset originale ed estraiamo latitudine e longitudine, infine salviamo tutto in una nuova nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_grid     = \"./Data/PowerGrid/gridkit_north_america-highvoltage-vertices_original.csv\"\n",
    "file_nodelist = \"./Data/PowerGrid/gridkit_north_america.nodelist\" # Qui ci sono i nuovi label\n",
    "file_label    = \"./Data/PowerGrid/old_new_labels.txt\"\n",
    "nodeslist     = pd.read_csv(file_nodelist, sep=\" \", names=[\"new_labels\", \"degree\"])\n",
    "labels        = pd.read_csv(file_label, header=None, sep=\" \", names=[\"old_labels\", \"new_labels\"])\n",
    "orig_data     = pd.read_csv(file_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva una nuova nodelist coi nuovi labels e latitudine e longitudine\n",
    "with open('node_coordinates.nodelist', 'w') as f:\n",
    "\n",
    "    for old_lab, new_lab in zip(labels[\"old_labels\"], labels[\"new_labels\"]):\n",
    "        ind = list(orig_data[\"v_id\"]).index(old_lab)    # Troviamo la riga corrispondente nel dataset originale\n",
    "        lat, lon = orig_data.iloc[ind][[\"lat\",\"lon\"]]   # Estraiamo latitudine e longitudine\n",
    "        f.write( str(new_lab) + \" \" + str(lat) + \" \" + str(lon) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggiungiamo una colonna con in nuovi label nel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEGGIAMO I DATI\n",
    "file_grid     = \"./Data/PowerGrid/gridkit_north_america-highvoltage-vertices_original.csv\"\n",
    "file_nodelist = \"./Data/PowerGrid/gridkit_north_america.nodelist\" # Qui ci sono i nuovi label\n",
    "file_label    = \"./Data/PowerGrid/old_new_labels.txt\"\n",
    "nodeslist     = pd.read_csv(file_nodelist, sep=\" \", names=[\"new_labels\", \"degree\"])\n",
    "labels        = pd.read_csv(file_label, header=None, sep=\" \", names=[\"old_labels\", \"new_labels\"])\n",
    "orig_data     = pd.read_csv(file_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict       = dict(zip(labels.old_labels, labels.new_labels))\n",
    "relabeled_vector = [int(label_dict[item]) if item in label_dict.keys() else np.nan for item in orig_data.v_id ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data.to_csv(\"./Data/PowerGrid/gridkit_north_america-highvoltage-vertices_original.csv\", sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip(labels.old_labels, labels.new_labels))\n",
    "# relabeled_vector = np.vectorize(label_dict.get)([3,13322,8105])   # ([3,13322,8105]) = (old_labels)\n",
    "relabeled_vector = np.vectorize(label_dict.get)(orig_data.v_id[0:1000])\n",
    "relabeled_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>Serial_Num.x</th>\n",
       "      <th>time</th>\n",
       "      <th>Season.x</th>\n",
       "      <th>Num.x</th>\n",
       "      <th>Basin.x</th>\n",
       "      <th>Sub_basin.x</th>\n",
       "      <th>Name.x</th>\n",
       "      <th>ISO_time.x</th>\n",
       "      <th>Nature.x</th>\n",
       "      <th>wmo_wind.x</th>\n",
       "      <th>wmo_pres.x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54593</th>\n",
       "      <td>-75.400002</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>2009147N31285</td>\n",
       "      <td>2009-05-26 18:00:00</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONE</td>\n",
       "      <td>2009-05-26 18:00:00</td>\n",
       "      <td>DS</td>\n",
       "      <td>25</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54594</th>\n",
       "      <td>-75.599998</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>2009147N31285</td>\n",
       "      <td>2009-05-27 00:00:00</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONE</td>\n",
       "      <td>2009-05-27 00:00:00</td>\n",
       "      <td>DS</td>\n",
       "      <td>25</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54595</th>\n",
       "      <td>-75.500000</td>\n",
       "      <td>32.700001</td>\n",
       "      <td>2009147N31285</td>\n",
       "      <td>2009-05-27 06:00:00</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONE</td>\n",
       "      <td>2009-05-27 06:00:00</td>\n",
       "      <td>DS</td>\n",
       "      <td>25</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            long        lat   Serial_Num.x                 time  Season.x  \\\n",
       "id                                                                          \n",
       "54593 -75.400002  30.600000  2009147N31285  2009-05-26 18:00:00      2009   \n",
       "54594 -75.599998  31.700001  2009147N31285  2009-05-27 00:00:00      2009   \n",
       "54595 -75.500000  32.700001  2009147N31285  2009-05-27 06:00:00      2009   \n",
       "\n",
       "       Num.x  Basin.x Sub_basin.x Name.x           ISO_time.x Nature.x  \\\n",
       "id                                                                       \n",
       "54593      1      NaN         NaN    ONE  2009-05-26 18:00:00       DS   \n",
       "54594      1      NaN         NaN    ONE  2009-05-27 00:00:00       DS   \n",
       "54595      1      NaN         NaN    ONE  2009-05-27 06:00:00       DS   \n",
       "\n",
       "       wmo_wind.x  wmo_pres.x  \n",
       "id                             \n",
       "54593          25        1010  \n",
       "54594          25        1010  \n",
       "54595          25        1010  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STORM_LIST  = ['INGRID', 'IRENE', 'EARL', 'KATE', 'SANDY', 'NATE', 'ISAAC', 'PAULA', 'MATTHEW', 'JOAQUIN', 'BILL', \n",
    "               'KATIA', 'HERMINE', 'ALEX', 'TOMAS', 'CRISTOBAL', 'IDA', 'KARL', 'ARTHUR', 'GONZALO', 'BERTHA']\n",
    "filepath = \"./US_storms_2009-2016.dat\"\n",
    "storm    = pd.read_csv(filepath,delimiter=\"|\",index_col=0)\n",
    "storm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test.csv\",\"w\") as file:\n",
    "    file.write(\"Name,MaxForceWind,Season\\n\")\n",
    "    for item in STORM_LIST:\n",
    "        df = storm.loc[storm[\"Name.x\"] == item]\n",
    "        max_wind = df.loc[:,\"wmo_wind.x\"].max()\n",
    "        season   = df.loc[:,\"Season.x\"].iloc[0]\n",
    "        file.write(f\"{item},{max_wind},{season}\\n\")\n",
    "# item = STORM_LIST[1]\n",
    "# df = storm.loc[storm[\"Name.x\"] == item]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 100\n",
    "x = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = []\n",
    "for i in range(0,n-1):\n",
    "    rec.append(x[:i+1].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
